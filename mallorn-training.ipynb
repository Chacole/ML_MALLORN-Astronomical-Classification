{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mallorn Challenge: Astronomical Time-Series Classification\n",
    "## Model: Feature Engineering + LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:03:49.716141Z",
     "iopub.status.busy": "2025-12-19T14:03:49.715845Z",
     "iopub.status.idle": "2025-12-19T14:03:49.722865Z",
     "shell.execute_reply": "2025-12-19T14:03:49.721844Z",
     "shell.execute_reply.started": "2025-12-19T14:03:49.716119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# C·∫•u h√¨nh hi·ªÉn th·ªã\n",
    "pd.set_option('display.max_columns', 500)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(f\"LightGBM version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CONFIG & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:03:49.724707Z",
     "iopub.status.busy": "2025-12-19T14:03:49.723945Z",
     "iopub.status.idle": "2025-12-19T14:03:49.847660Z",
     "shell.execute_reply": "2025-12-19T14:03:49.847025Z",
     "shell.execute_reply.started": "2025-12-19T14:03:49.724689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ƒê∆∞·ªùng d·∫´n (T·ª± ƒë·ªông t√¨m)\n",
    "    INPUT_ROOT = '/kaggle/input'\n",
    "    WORKING_DIR = '/kaggle/working'\n",
    "\n",
    "    # N·∫øu ch·∫°y l·∫ßn ƒë·∫ßu: ƒë·ªÉ None\n",
    "    # N·∫øu ch·∫°y l·∫ßn 2: ƒëi·ªÅn ƒë∆∞·ªùng d·∫´n dataset ch·ª©a output l·∫ßn 1 (VD: '/kaggle/input/mallorn-part1-output')\n",
    "    RESUME_PATH = None \n",
    "    # RESUME_PATH = '/kaggle/input/my-previous-output-dataset'\n",
    "\n",
    "    # Model Params\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "    target_col = 'target'\n",
    "    id_col = 'object_id'\n",
    "    \n",
    "    # LightGBM Hyperparameters\n",
    "    lgb_params = {\n",
    "        'objective': 'binary', # Ho·∫∑c 'multiclass' n·∫øu > 2 l·ªõp\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "\n",
    "        # H·ªçc ch·∫≠m l·∫°i ƒë·ªÉ t√¨m ƒëi·ªÉm t·ªëi ∆∞u t·ªët h∆°n\n",
    "        'learning_rate': 0.03, \n",
    "\n",
    "        # Ki·ªÉm so√°t ƒë·ªô ph·ª©c t·∫°p (Tr√°nh Overfitting)\n",
    "        'num_leaves': 31,        # Model ƒë∆°n gi·∫£n h∆°n s·∫Ω t·ªïng qu√°t t·ªët h∆°n\n",
    "        'max_depth': -1,          # Gi·ªõi h·∫°n ƒë·ªô s√¢u c√¢y (ƒëang ƒë·ªÉ t·ª± do)\n",
    "        'min_data_in_leaf': 20,\n",
    "\n",
    "        # Regularization (Ph·∫°t model n·∫øu tr·ªçng s·ªë qu√° l·ªõn)\n",
    "        'lambda_l1': 0.05,        # L1 Regularization\n",
    "        'lambda_l2': 0.05,        # L2 Regularization\n",
    "\n",
    "        # Sampling (Gi√∫p model kh√¥ng nh√¨n th·∫•y to√†n b·ªô data m·ªói l·∫ßn -> ch·ªëng h·ªçc v·∫πt)\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'is_unbalance': True # Quan tr·ªçng v√¨ dataset m·∫•t c√¢n b·∫±ng (0 >> 1)\n",
    "    }\n",
    "\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "# H√†m t√¨m dataset\n",
    "def find_files():\n",
    "    \"\"\"Qu√©t to√†n b·ªô th∆∞ m·ª•c ƒë·ªÉ t√¨m file logs v√† lightcurves\"\"\"\n",
    "    train_log_path = None\n",
    "    test_log_path = None\n",
    "    sample_sub_path = None\n",
    "    \n",
    "    # T√¨m file logs ch√≠nh\n",
    "    for root, dirs, files in os.walk(CFG.INPUT_ROOT):\n",
    "        if 'train_log.csv' in files:\n",
    "            train_log_path = os.path.join(root, 'train_log.csv')\n",
    "        if 'test_log.csv' in files:\n",
    "            test_log_path = os.path.join(root, 'test_log.csv')\n",
    "        if 'sample_submission.csv' in files:\n",
    "            sample_sub_path = os.path.join(root, 'sample_submission.csv')\n",
    "            \n",
    "    print(f\"Train Log: {train_log_path}\")\n",
    "    print(f\"Test Log: {test_log_path}\")\n",
    "    \n",
    "    # T√¨m c√°c file lightcurves trong c√°c th∆∞ m·ª•c split\n",
    "    # Logic: C√≥ th·ªÉ c√≥ nhi·ªÅu file tr√πng t√™n trong c√°c split, ta s·∫Ω gom h·∫øt\n",
    "    lc_files = glob.glob(os.path.join(CFG.INPUT_ROOT, '**', '*_full_lightcurves.csv'), recursive=True)\n",
    "    print(f\"Found {len(lc_files)} lightcurve files.\")\n",
    "    \n",
    "    return train_log_path, test_log_path, sample_sub_path, lc_files\n",
    "\n",
    "train_log_path, test_log_path, sample_sub_path, lc_files = find_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Loading & Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:03:49.848522Z",
     "iopub.status.busy": "2025-12-19T14:03:49.848282Z",
     "iopub.status.idle": "2025-12-19T14:03:52.148232Z",
     "shell.execute_reply": "2025-12-19T14:03:52.147411Z",
     "shell.execute_reply.started": "2025-12-19T14:03:49.848496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=== Loading Metadata (Logs) ===\")\n",
    "# ƒê·ªçc Metadata (Labels, Z, EBV...)\n",
    "if train_log_path:\n",
    "    train_meta = pd.read_csv(train_log_path)\n",
    "    print(f\"Train Meta Shape: {train_meta.shape}\")\n",
    "    display(train_meta.head(3))\n",
    "else:\n",
    "    raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y train_log.csv!\")\n",
    "\n",
    "if test_log_path:\n",
    "    test_meta = pd.read_csv(test_log_path)\n",
    "    print(f\"Test Meta Shape: {test_meta.shape}\")\n",
    "else:\n",
    "    print(\"Warning: Test log not found.\")\n",
    "\n",
    "print(\"\\n=== Loading Lightcurves (This may take a while) ===\")\n",
    "# Chi·∫øn thu·∫≠t: ƒê·ªçc sample ƒë·ªÉ ki·ªÉm tra c·ªôt, sau ƒë√≥ ƒë·ªçc v√† concat\n",
    "# L∆∞u √Ω: V√¨ file c√≥ th·ªÉ r·∫•t l·ªõn, ta ch·ªâ ƒë·ªçc nh·ªØng c·ªôt c·∫ßn thi·∫øt\n",
    "dfs = []\n",
    "cols_to_use = ['object_id', 'Time (MJD)', 'Flux', 'Flux_err', 'Filter']\n",
    "\n",
    "# Thanh ti·∫øn tr√¨nh ƒë·ªçc file\n",
    "for f in tqdm(lc_files, desc=\"Reading LC files\"):\n",
    "    try:\n",
    "        # Ki·ªÉm tra xem file l√† train hay test ƒë·ªÉ t·ªëi ∆∞u (t√πy ch·ªçn)\n",
    "        df_chunk = pd.read_csv(f, usecols=lambda c: c in cols_to_use)\n",
    "        dfs.append(df_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "if dfs:\n",
    "    full_lc = pd.concat(dfs, ignore_index=True)\n",
    "    # Lo·∫°i b·ªè duplicate n·∫øu c√°c split ch·ª©a d·ªØ li·ªáu tr√πng l·∫∑p\n",
    "    full_lc = full_lc.drop_duplicates()\n",
    "    print(f\"Total Lightcurve Points: {len(full_lc)}\")\n",
    "    display(full_lc.head())\n",
    "else:\n",
    "    raise ValueError(\"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu Lightcurve n√†o!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:03:52.150154Z",
     "iopub.status.busy": "2025-12-19T14:03:52.149939Z",
     "iopub.status.idle": "2025-12-19T14:04:01.617834Z",
     "shell.execute_reply": "2025-12-19T14:04:01.617239Z",
     "shell.execute_reply.started": "2025-12-19T14:03:52.150136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "feature_file_name = 'extracted_features.csv'\n",
    "loaded_features = False\n",
    "\n",
    "# 1. Ki·ªÉm tra Resume (Session c≈©)\n",
    "if CFG.RESUME_PATH and os.path.exists(os.path.join(CFG.RESUME_PATH, feature_file_name)):\n",
    "    print(f\"üîÑ Found saved features in Input: {CFG.RESUME_PATH}\")\n",
    "    lc_features = pd.read_csv(os.path.join(CFG.RESUME_PATH, feature_file_name))\n",
    "    loaded_features = True\n",
    "\n",
    "# 2. Ki·ªÉm tra Working Dir (Session hi·ªán t·∫°i)\n",
    "elif os.path.exists(os.path.join(CFG.WORKING_DIR, feature_file_name)):\n",
    "    print(f\"üîÑ Found saved features in Working Directory\")\n",
    "    lc_features = pd.read_csv(os.path.join(CFG.WORKING_DIR, feature_file_name))\n",
    "    loaded_features = True\n",
    "\n",
    "# 3. T√≠nh to√°n m·ªõi\n",
    "if not loaded_features:\n",
    "    print(\"‚ö° No cached features found. Starting extraction (This takes time)...\")\n",
    "    \n",
    "    def extract_features(lc_df):\n",
    "        print(\"Extracting features (Phase 2: Advanced Statistics)...\")\n",
    "        \n",
    "        # 1. Th·ªëng k√™ chung (Global Stats)\n",
    "        aggs = {\n",
    "            'Flux': [\n",
    "                'min', 'max', 'mean', 'std', 'skew', \n",
    "                lambda x: np.percentile(x, 25), \n",
    "                lambda x: np.percentile(x, 50), \n",
    "                lambda x: np.percentile(x, 75), \n",
    "                lambda x: np.percentile(x, 95) - np.percentile(x, 5)\n",
    "            ],\n",
    "            'Flux_err': ['mean', 'max'],\n",
    "            'Time (MJD)': [lambda x: x.max() - x.min(), 'count']\n",
    "        }\n",
    "        \n",
    "        features = lc_df.groupby('object_id').agg(aggs)\n",
    "        features.columns = ['_'.join(col).strip() for col in features.columns.values]\n",
    "        \n",
    "        rename_dict = {\n",
    "            'Flux_<lambda_0>': 'flux_q25',\n",
    "            'Flux_<lambda_1>': 'flux_median',\n",
    "            'Flux_<lambda_2>': 'flux_q75',\n",
    "            'Flux_<lambda_3>': 'flux_range90',\n",
    "            'Time (MJD)_<lambda_0>': 'duration',\n",
    "            'Time (MJD)_count': 'n_obs'\n",
    "        }\n",
    "        features.rename(columns=rename_dict, inplace=True)\n",
    "        \n",
    "        # 2. Pivot Table (Filter Stats)\n",
    "        pivot_stats = pd.pivot_table(lc_df, index='object_id', columns='Filter', \n",
    "                                     values=['Flux'], # D√πng list\n",
    "                                     aggfunc=['mean', 'std', 'max', 'min'])\n",
    "        \n",
    "        # ƒê·∫∑t t√™n c·ªôt d·∫°ng: u_mean_Flux, g_std_Flux... (Filter_Agg_Value)\n",
    "        # col[2]=Filter, col[1]=Agg, col[0]=Value\n",
    "        pivot_stats.columns = [f\"{col[2]}_{col[1]}_{col[0]}\" for col in pivot_stats.columns.values]\n",
    "        \n",
    "        # 3. T√≠nh Color Index\n",
    "        bands = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "        for i in range(len(bands)-1):\n",
    "            b1, b2 = bands[i], bands[i+1]\n",
    "            # V√¨ ta ƒë√£ ƒë·∫∑t t√™n c·ªôt l√† u_mean_Flux n√™n d√πng startswith('u') l√† chu·∫©n\n",
    "            c1 = [c for c in pivot_stats.columns if c.startswith(b1) and 'mean' in c]\n",
    "            c2 = [c for c in pivot_stats.columns if c.startswith(b2) and 'mean' in c]\n",
    "            \n",
    "            if c1 and c2:\n",
    "                features[f'color_{b1}-{b2}'] = pivot_stats[c1[0]] - pivot_stats[c2[0]]\n",
    "\n",
    "        # Merge l·∫°i\n",
    "        final_features = features.merge(pivot_stats, on='object_id', how='left')\n",
    "        \n",
    "        # 4. Ratios\n",
    "        final_features['flux_std_over_mean'] = final_features['Flux_std'] / (final_features['Flux_mean'].abs() + 1e-6)\n",
    "        final_features['amplitude'] = final_features['Flux_max'] - final_features['Flux_min']\n",
    "        \n",
    "        return final_features\n",
    "\n",
    "    # Ki·ªÉm tra bi·∫øn\n",
    "    if 'full_lc' not in globals():\n",
    "        raise NameError(\"Bi·∫øn 'full_lc' ch∆∞a ƒë∆∞·ª£c t·∫°o. H√£y ch·∫°y l·∫°i Cell 4!\")\n",
    "\n",
    "    # Th·ª±c thi\n",
    "    lc_features = extract_features(full_lc)\n",
    "    \n",
    "    # Save\n",
    "    save_path = os.path.join(CFG.WORKING_DIR, feature_file_name)\n",
    "    lc_features.to_csv(save_path, index=True)\n",
    "    print(f\"üíæ Features saved to: {save_path}\")\n",
    "\n",
    "    del full_lc, dfs\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"Features shape: {lc_features.shape}\")\n",
    "display(lc_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Prepare Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:04:01.618822Z",
     "iopub.status.busy": "2025-12-19T14:04:01.618547Z",
     "iopub.status.idle": "2025-12-19T14:04:01.640582Z",
     "shell.execute_reply": "2025-12-19T14:04:01.639959Z",
     "shell.execute_reply.started": "2025-12-19T14:04:01.618798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=== Preparing Final Datasets ===\")\n",
    "\n",
    "# Merge features v·ªõi Metadata (Z, EBV)\n",
    "# Train Set\n",
    "train_df = train_meta.merge(lc_features, on='object_id', how='left')\n",
    "# Test Set\n",
    "test_df = test_meta.merge(lc_features, on='object_id', how='left')\n",
    "\n",
    "# Drop c√°c c·ªôt kh√¥ng d√πng train (Text, SpecType, split)\n",
    "drop_cols = ['SpecType', 'English Translation', 'split', 'target', 'object_id']\n",
    "# Gi·ªØ l·∫°i danh s√°ch Feature\n",
    "feature_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "print(f\"Features used for training ({len(feature_cols)}):\")\n",
    "print(feature_cols[:10], \"...\")\n",
    "\n",
    "# Check target\n",
    "print(\"Target Distribution:\")\n",
    "print(train_df['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Training Model (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:04:01.641728Z",
     "iopub.status.busy": "2025-12-19T14:04:01.641411Z",
     "iopub.status.idle": "2025-12-19T14:04:05.854795Z",
     "shell.execute_reply": "2025-12-19T14:04:05.853960Z",
     "shell.execute_reply.started": "2025-12-19T14:04:01.641711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"=== Starting Training with Resume Logic ===\")\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['target']\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "models = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n--- Fold {fold+1}/{CFG.n_folds} ---\")\n",
    "    \n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # T√™n file model cho Fold n√†y\n",
    "    model_filename = f\"lgb_model_fold_{fold}.txt\"\n",
    "    \n",
    "    # 1. T√¨m model trong RESUME_PATH (∆Øu ti√™n load t·ª´ session tr∆∞·ªõc)\n",
    "    resume_model_path = os.path.join(CFG.RESUME_PATH, model_filename) if CFG.RESUME_PATH else None\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    if resume_model_path and os.path.exists(resume_model_path):\n",
    "        print(f\"üîÑ Resuming: Loading existing model from {resume_model_path}\")\n",
    "        model = lgb.Booster(model_file=resume_model_path)\n",
    "    else:\n",
    "        # 2. N·∫øu kh√¥ng c√≥, Train m·ªõi\n",
    "        print(f\"‚ö° Training New Model for Fold {fold+1}...\")\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
    "\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
    "        \n",
    "        callbacks = [\n",
    "            # TƒÉng ki√™n nh·∫´n t·ª´ : Model s·∫Ω ƒë·ª£i l√¢u h∆°n xem loss c√≥ gi·∫£m ti·∫øp kh√¥ng\n",
    "            lgb.early_stopping(stopping_rounds=100), \n",
    "            # In log m·ªói 500 v√≤ng cho ƒë·ª° r·ªëi m·∫Øt\n",
    "            lgb.log_evaluation(period=500)\n",
    "        ]\n",
    "\n",
    "        # Train\n",
    "        model = lgb.train(\n",
    "            CFG.lgb_params,\n",
    "            dtrain,\n",
    "            valid_sets=[dtrain, dval],\n",
    "            # TƒÉng s·ªë v√≤ng t·ªëi ƒëa t·ª´ ƒë·ªÉ ph√π h·ª£p v·ªõi Learning Rate th·∫•p\n",
    "            num_boost_round=5000, \n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        # L∆∞u model ngay sau khi train xong\n",
    "        save_path = os.path.join(CFG.WORKING_DIR, model_filename)\n",
    "        model.save_model(save_path)\n",
    "        print(f\"üíæ Model saved to {save_path}\")\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    # Predict\n",
    "    val_probs = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_preds[val_idx] = val_probs\n",
    "    \n",
    "    test_preds += model.predict(X_test, num_iteration=model.best_iteration) / CFG.n_folds\n",
    "    \n",
    "    # === T√åM THRESHOLD T·ªêI ∆ØU CHO FOLD N√ÄY ===\n",
    "    best_f1 = 0\n",
    "    best_thr = 0.5\n",
    "    for thr in np.arange(0.1, 0.9, 0.05):\n",
    "        current_f1 = f1_score(y_val, (val_probs > thr).astype(int), average='macro')\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_thr = thr\n",
    "            \n",
    "    print(f\"Fold {fold+1} Best Threshold: {best_thr:.2f} | F1-Macro: {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\n=== Training Finished ===\")\n",
    "\n",
    "# === T√åM THRESHOLD T·ªîNG TH·ªÇ ===\n",
    "best_global_f1 = 0\n",
    "best_global_thr = 0.5\n",
    "for thr in np.arange(0.1, 0.9, 0.01):\n",
    "    current_f1 = f1_score(y, (oof_preds > thr).astype(int), average='macro')\n",
    "    if current_f1 > best_global_f1:\n",
    "        best_global_f1 = current_f1\n",
    "        best_global_thr = thr\n",
    "\n",
    "print(f\"\\nüèÜ OVERALL Best Threshold: {best_global_thr:.2f}\")\n",
    "print(f\"üèÜ OVERALL CV F1-Macro: {best_global_f1:.4f}\")\n",
    "\n",
    "# C·∫≠p nh·∫≠t l·∫°i k·∫øt qu·∫£ submission v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u n√†y\n",
    "final_preds_labels = (test_preds > best_global_thr).astype(int)\n",
    "\n",
    "print(\"\\n=== Training Finished ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Evaluation & Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:04:05.855988Z",
     "iopub.status.busy": "2025-12-19T14:04:05.855701Z",
     "iopub.status.idle": "2025-12-19T14:04:06.206074Z",
     "shell.execute_reply": "2025-12-19T14:04:06.205242Z",
     "shell.execute_reply.started": "2025-12-19T14:04:05.855970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ƒê√°nh gi√° t·ªïng th·ªÉ\n",
    "oof_labels = (oof_preds > 0.5).astype(int)\n",
    "overall_f1 = f1_score(y, oof_labels, average='macro')\n",
    "overall_acc = accuracy_score(y, oof_labels)\n",
    "\n",
    "print(f\"Overall CV F1-Macro: {overall_f1:.4f}\")\n",
    "print(f\"Overall CV Accuracy: {overall_acc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y, oof_labels))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, oof_labels))\n",
    "\n",
    "# Plot Feature Importance\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance[\"feature\"] = feature_cols\n",
    "feature_importance[\"importance\"] = sum([m.feature_importance() for m in models])\n",
    "feature_importance = feature_importance.sort_values(by=\"importance\", ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance)\n",
    "plt.title(\"Top 20 Important Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:04:06.208047Z",
     "iopub.status.busy": "2025-12-19T14:04:06.207796Z",
     "iopub.status.idle": "2025-12-19T14:04:06.235918Z",
     "shell.execute_reply": "2025-12-19T14:04:06.235099Z",
     "shell.execute_reply.started": "2025-12-19T14:04:06.208015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=== Generating Submission ===\")\n",
    "\n",
    "# Chuy·ªÉn x√°c su·∫•t th√†nh nh√£n (0/1) \n",
    "final_preds_labels = (test_preds > 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'object_id': test_df['object_id'],\n",
    "    'prediction': final_preds_labels \n",
    "})\n",
    "\n",
    "# Ki·ªÉm tra format v·ªõi sample_submission n·∫øu c√≥\n",
    "if sample_sub_path:\n",
    "    sample_sub = pd.read_csv(sample_sub_path)\n",
    "    # ƒê·∫£m b·∫£o th·ª© t·ª± object_id kh·ªõp (n·∫øu c·∫ßn thi·∫øt, th∆∞·ªùng Kaggle ch·∫•m theo ID n√™n merge l√† an to√†n nh·∫•t)\n",
    "    submission = submission.set_index('object_id').reindex(sample_sub['object_id']).reset_index()\n",
    "    # Fill missing n·∫øu c√≥ (ph√≤ng tr∆∞·ªùng h·ª£p test_log thi·∫øu ID so v·ªõi sample)\n",
    "    submission['prediction'] = submission['prediction'].fillna(0).astype(int)\n",
    "\n",
    "output_path = os.path.join(CFG.WORKING_DIR, 'submission.csv')\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {output_path}\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9073653,
     "sourceId": 14223785,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
